# Aspect-Oriented Opinion Summarization of Yelp Reviews

This repository contains source code for various experiments to explore the feasibility of using business aspects to generate review summaries.

## Install dependencies

```sh
pip install -r requirements.txt
```

## Download Data

Our project uses Yelp Dataset, consisting of over 6.9 million reviews and 150k businesses. To download the dataset, visit [Yelp Dataset](https://www.yelp.com/dataset).

## Process Data

The downloaded dataset requires some preprocessing before we can use it. It involves filtering out low rating businesses, remove excessively long or short reviews, etc.

Requirements:

- 5 GB free disk space
- 8 vCPUs with 64 GB RAM

Before running the preprocessing script, make sure to untar the downloaded data:

```sh
mkdir data
tar -xvf yelp_dataset.tar -C ./data
```

Now run the following commands to process the data.
Processing will take about 10 minutes.

```sh
cd src

# --data_root: directory containing untar yelp dataset json files
python process_data.py --data_root ./data
```

## Make Mini-Dataset

For experimentation, let's create a mini-dataset.

```sh
cd src

python make_dataset.py --data_file ./data/processed_dataset.json --out_dir ./data
```

## Download Test Dataset

To evaluate our generated dataset, prompts, and fine-tuned models, we use Yelp dataset released by Brazinskas et al. (2020). The dataset contains 100 human-written summaries generated by Amazon Mechanical Turk (AMT) workers, who summaried 8 reviews per business. Each business has 3 generated summaries by 3 workers, one summary per worker.

To download the dataset, run:

```sh
mkdir ./data/gold_summs

curl "https://raw.githubusercontent.com/abrazinskas/FewSum/master/artifacts/yelp/gold_summs/train.csv" --output "./data/gold_summs/train.csv"

curl "https://raw.githubusercontent.com/abrazinskas/FewSum/master/artifacts/yelp/gold_summs/val.csv" --output "./data/gold_summs/val.csv"

curl "https://raw.githubusercontent.com/abrazinskas/FewSum/master/artifacts/yelp/gold_summs/test.csv" --output "./data/gold_summs/test.csv"

curl "https://s3.us-east-2.amazonaws.com/unsup-sum/summaries_0-200_cleaned.csv" --output "./data/chu_dataset.csv"
```

## Preprocess Test Dataset

Now process the downloaded test dataset. This includes merging train/val/test splits together to make an evaluation dataset of human-written summaries; 100 businesses, 800 reviews, and 300 summaries.

```sh
cd src

python process_eval_dataset.py --data_root ./data/gold_summs --out_dir ./data
```
